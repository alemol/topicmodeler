#######################################
# Opciones de parametrización de VSPACE

[VSPACE]

#######################################
# exclude_words str – La ruta de un archivo con los n-gramas a excluir en la generación del modelo vectorial.

exclude_words="/Users/amolina/repo/topicmodeler/resources/stopwords_MX.txt"

#######################################
# Opciones de parametrización de LDA

[LDA]

#######################################
# num_topics (int, optional) – El número de topics a extraer del corpus de entrenamiento.
# y
#num_topics=10

#######################################
# iterations (int, optional) – Máximo de iteraciones en el corpus en la inferencia de la distribución de topics.
# y
#iterations=5000

#######################################
# alpha ({numpy.ndarray, str}, optional) – Es el valor del hyperparámetro de la distribución de Dirichlet para las probabilidades de los documentos en los topics (theta en la literatura).
# Puede ser inicializado mediante un arreglo 1D cuya longitud sea igual al número de temas esperados de manera que cada entrada en el arreglo expresa la probabilidad a priori esperada para cada topic. 
# Alternativamente se puede usar como valor alguna de las siguientes estrategias:
# auto : aprende la asimetría de las probabilidades a priori a partir del corpus (ADVERTENCIA, no tendrá efecto si distributed==True). 
# asymmetric : utiliza 1.0 / topicno como probabilidades apriori.
# n
alpha=asymmetric
#alpha=0.5

# eta ({float, np.array, str}, optional) – Es el valor del hyperparámetro de la distribución de Dirichlet para las probabilidades de las palabras en los topics (phi en la literatura).
# Puede ser inicializado mediante:
# auto : aprende la asimetría de las probabilidades a priori a partir del corpus;
# un escalar para un prior simétrico sobre topic/word probability;
# un arreglo 1D cuya longitud sea igual a num_words de manera que cada entrada en el arreglo expresa la probabilidad a priori esperada para cada palabra;
# matriz (num_topics, num_words) para asignar una probabilidad para cada combinación palabra-topic.
# n
#eta=auto
#eta=0.05
#eta=0.08
#*eta=0.075
eta=0.080


#######################################
# distributed (bool, optional) – Indica si debe usarse cómputo distribuido para acelerar el entrenamiento si el valor es True , cuando es False afecta al parámetro alpha porque no se puede usar con valor auto.
#distributed=False

# eval_every (int, optional) – Cada cuantos updates se debe estimar la Log perplexity.
# ADEVERTENCIA, el valor de 1 alenta el proceso de entrenamiento en O(2x).
# n
eval_every=1

#######################################
# update_every (int, optional) – Número de documentos a ser iterados por cada actualización; el valor 0 indica "batch learning" mientras que , > 1 indica "online iterative learning".
#update_every=10

#######################################
# passes (int, optional) – Número de pasadas a través del corpus durante el entrenamiento.
# y
# passes=15

#######################################
# topn (int) – Number of words from topic that will be used in show_topic_terms, get_topic_terms, print_topic

#topn=100

#######################################
# chunksize (int, optional) – Número de documentos a utilizar en cada chunk de entrenamiento.

#chunksize=1


#######################################
# decay (float, optional) – Un número entre (0.5, 1] ponderando el porcentaje del valor previo de lambda a olvidar cuando cada nuevo doc es examinado.
# Corresponde al valor de Kappa de Matthew D. Hoffman, David M. Blei, Francis Bach: “Online Learning for Latent Dirichlet Allocation NIPS‘10”.

#######################################
# offset (float, optional) – Controla cuánto ralentizar los primeros pasos en las primeras iteraciones.
# Corresponde al valor de Tau_0 de Matthew D. Hoffman, David M. Blei, Francis Bach: “Online Learning for Latent Dirichlet Allocation NIPS‘10”.

#######################################
# gamma_threshold (float, optional) – Cambio mínimo en el valor de parámetros gamma para continuar iterando.

#######################################
# minimum_probability (float, optional) – Los topics con probabilidades menores que este parámetro serán eliminados.

#######################################
# random_state ({np.random.RandomState, int}, optional) – Un objeto randomState o una semilla para generar uno útil para reproducir resultados.

#######################################
# ns_conf (dict of (str, object), optional) – Key word parámetros propagados a gensim.utils.getNS() para tener un Pyro4 Nameserved, solamente se usa cuando 
#n
#distributed==True

#######################################
# minimum_phi_value (float, optional) – si per_word_topics==True, representa un límite inferior a las probabilidades de los términos.

#######################################
# per_word_topics (bool) – si es True, el modelo también genera una lista de topics, ordenados en descendiente del topic más probable aunado con sus valores phi multiplicados por el tamaño del feature (word count).

#######################################
# callbacks (list of Callback) – Callbacks de métricas para log y visualizacion del modelo durante el entrenamiento.

#######################################
# dtype ({numpy.float16, numpy.float32, numpy.float64}, optional) – Tipo de dato usado para los cálculos.
